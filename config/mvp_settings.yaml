# Config/mvp_settings.yaml
# Configuration minimale pour le MVP P0

stt:
  model_name: "openai/whisper-base" # Modèle plus léger pour les tests
  gpu_device: "cuda:0" # Cible la RTX 3090/5060Ti

llm:
  model_path: "D:/modeles_llm/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/Nous-Hermes-2-Mistral-7B-DPO.Q4_K_S.gguf" # Modèle existant 7B
  gpu_device_index: 0 # Cible la RTX 3090/5060Ti
  n_gpu_layers: -1 # Décharger toutes les couches sur le GPU

tts:
  # Configuration pour Piper-TTS local (100% offline, conforme LUXA)
  model_path: "models/fr_FR-siwis-medium.onnx"
  use_gpu: true
  sample_rate: 22050 